# study_oml
> [OML](https://open-metric-learning.readthedocs.io/en/latest/index.html)

>> [Training](https://colab.research.google.com/drive/1kntDAIdIZ9L40jcndguLAb-XqmCFOgS5?usp=sharing)
```
# https://open-metric-learning.readthedocs.io/en/latest/contents/utils.html#download-mock-dataset
dataset_root = "mock_dataset/"
df_train, _ = download_mock_dataset(dataset_root)
df_train.head()
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/ae6c2e91-b44a-469c-bd63-32bcecc8456d)
Return: train과 validation Dataframe
>>> 구조 (8x3)


![image](https://github.com/Suyeon-j/study_oml/assets/66247203/ba0849ad-4d36-42db-96ad-615fea39551f)


```
# https://open-metric-learning.readthedocs.io/en/latest/contents/models.html#vitextractor
# 03
model = ViTExtractor("vits16_dino", arch="vits16", normalise_features=False).train()
model
```
ViTExtractor(weights(사전 훈련된 가중치 지정 매개변수), arch(모델 아키텍처 선택), normalise_features(특성 정규화 여부)): [Visual Transformer 아키텍처](https://gaussian37.github.io/dl-concept-vit/)를 따르는 추출기의 기본 클래스
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/99d36ddd-809c-4933-93ef-530d90d028e3)

```
# https://pytorch.org/docs/stable/generated/torch.optim.SGD.html
# 05
optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)
optimizer
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/3673524f-5ec8-43b2-abee-05368a180674)

```
# https://open-metric-learning.readthedocs.io/en/latest/contents/datasets.html#datasetwithlabels
# 01
train_dataset = DatasetWithLabels(df_train, dataset_root=dataset_root)
train_dataset.df
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/2d180786-09ff-47c6-ab2e-fb91c476c8dd)


```
# https://open-metric-learning.readthedocs.io/en/latest/contents/losses.html#tripletlosswithminer
# 04
criterion = TripletLossWithMiner(margin=0.1, miner=AllTripletsMiner(), need_logs=True)
criterion
```
TripletLossWithMiner(margin(triplet loss의 마진 설정), miner(triplet을 생성하는데 사용되는 miner를 지정하는 함수), need_logs(로그 기록 여부)): Miner and TripletLoss 조합

```
# https://open-metric-learning.readthedocs.io/en/latest/contents/samplers.html#balancesampler
# 02-01
sampler = BalanceSampler(train_dataset.get_labels(), n_labels=2, n_instances=2)
print(sampler.lbl2idx)
print(sampler.batch_size)
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/5ebb9660-9554-41f3-b92c-daeac3529851)

BalanceSampler(labels, n_labels, n_instances): n_instances x n_labels 형태 배치 생성

```
# https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader
# 02-02
train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=sampler)
train_loader
```
DataLoader(): 데이터셋을 읽어와서 배치단위로 데이터 불러옴

```
for batch in tqdm(train_loader):
    embeddings = model(batch["input_tensors"])
    loss = criterion(embeddings, batch["labels"])
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    # info for logging: positive/negative distances, number of active triplets
    print(criterion.last_logs)
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/7eebc98d-c611-4df7-809d-5919425ad760)

active_tri: 활성화된 Triplets(Triplet Loss 함수에서 실제로 모델이 학습하고 있는 경우)의 비율을 나타내는 지표

높을수록 유효한 정보를 뽑아냈다고 할 수 있음

>> [Validation](https://colab.research.google.com/drive/1O2o3k8I8jN5hRin3dKnAS3WsgG04tmIT?usp=sharing)
```
# https://open-metric-learning.readthedocs.io/en/latest/contents/utils.html#download-mock-dataset
dataset_root =  "mock_dataset/"
_, df_val = download_mock_dataset(dataset_root)
df_val.head()
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/5c0a1608-5e68-4860-85ca-65132e4fec82)
구조: training과 동일

```
# https://open-metric-learning.readthedocs.io/en/latest/contents/models.html#vitextractor
model = ViTExtractor("vits16_dino", arch="vits16", normalise_features=False).eval()
model
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/1474294c-6c5d-47f7-9390-02d6dc48b411)

```
# https://open-metric-learning.readthedocs.io/en/latest/contents/datasets.html#datasetquerygallery
val_dataset = DatasetQueryGallery(df_val, dataset_root=dataset_root)
val_dataset.df
```
DatasetQueryGallery(df, dataset_root): 쿼리와 갤러리 분할 정보 제공
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/d8e6c3ee-b6d5-489e-8dd4-b0bedfc17e77)

```
# https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4)
```
training과 달리 손실함수(triplet)을 사용하지 않기 때문에 데이터 샘플링을 할 필요가 없음 -> batch_sampler 대신 batch_size 사용

DatasetQueryGallery(): 검증 단계에서 데이터 세트로 사용하기 위해 쿼리/갤러리 분할 정보를 넘겨줘야함 +) 유효성 검사 프로세스를 수행할 때 데이터셋이 분할 정보를 포함하고 있지않다면 is_query와 is_gallery가 모두 True여야 함

```
# https://open-metric-learning.readthedocs.io/en/latest/contents/metrics.html#embeddingmetrics
calculator = EmbeddingMetrics(extra_keys=["paths",])
calculator.setup(num_samples=len(val_dataset))
```
EmbeddingMetrics(extra_keys(배치에서 몇가지 정보를 추가 정보를 축적하는 키)): 매 배치마다 모델이 생성한 배치와 임베딩에서 얻은 정보를 에포크 단위로 축적

calculator.setup(num_samples=len(val_dataset)): self.update_data() 첫 호출 전에 호출해야 함

```
# https://open-metric-learning.readthedocs.io/en/latest/contents/metrics.html#oml.metrics.embeddings.EmbeddingMetrics.update_data
with torch.no_grad():
    for batch in tqdm(val_loader):
        batch["embeddings"] = model(batch["input_tensors"])
        calculator.update_data(batch)
```
calculator.update_data(): 나중에 메트릭을 계산하기 위해 데이터를 전달하는 메소드

![image](https://github.com/Suyeon-j/study_oml/assets/66247203/1bc6a59c-3616-46c3-95d3-bb882e0b04a2)


```
# Logging
print(calculator.metrics)  # metrics
print(calculator.metrics_unreduced)  # metrics without averaging over queries(쿼리에 대한 평균을 사용하지 않음)
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/092099ff-d1d6-4c47-ae00-28dd9ebf4a7c)
cmc: 쿼리까지의 거리로 정렬된 상위 k 갤러리 인스턴스에 이 쿼리와 관련된 인스턴스가 하나 이상 있는 경우 1, 그렇지 않은 경우 0 (cmc@k: 각 쿼리에 대해 계산된 결과 평균)
map: 평균 정밀도를 계산하는 함수(map@k: recall의 함수로 간주되는 정밀도의 평균 값)
pcf: 주성분 분석을 사용해 임베딩의 주성분 비율을 추정(metric은 데이터의 필요한 분산을 설명하는데 필요한 성분의 비율로 정의)
precision: 정밀도(precision@k: 쿼리에서 갤러리까지의 거리로 정렬된 상위 k개 인스턴스 중 관련 갤러리 인스턴스의 일부)

```
import matplotlib.pyplot as plt

# Visualisation
# https://open-metric-learning.readthedocs.io/en/latest/contents/metrics.html#oml.metrics.embeddings.EmbeddingMetrics.get_plot_for_queries
print("Draw predictions for predefined queries")
calculator.get_plot_for_queries(query_ids=[2, 1], n_instances=5, verbose=False)
plt.show()
```
calculator.get_plot_for_queries(query_ids, n_instances, verbose): <query_ids> 표시를 사용하여 쿼리에 대한 예측을 시각화
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/e9f3926f-d019-44af-bde9-52b87c27d754)

+) verbose=True
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/3dad42f3-a682-4f1e-99b9-34ddaffccb46)


```
print("Draw the queries worst by map@5")
calculator.get_plot_for_worst_queries(metric_name="OVERALL/map/5", n_queries=2, n_instances=5, verbose=False)
plt.show()
```
calculator.get_plot_for_worst_queries(): map@5로 최악의 쿼리 그리기

![image](https://github.com/Suyeon-j/study_oml/assets/66247203/080d40f3-bba6-4bc6-a1a5-62e2254cf8f9)


