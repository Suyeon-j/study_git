> 01. epoch에 따른 val 변화 (train+validation)
   ```
# 방법 01
pl_model = ExtractorModule(model, criterion, optimizer)
trainer = pl.Trainer(max_epochs=5, callbacks=[metric_callback], num_sanity_val_steps=0, logger=logger, check_val_every_n_epoch=1)
trainer.fit(pl_model, train_dataloaders=train_loader, val_dataloaders=val_loader)
   ```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/06877ee4-9430-4923-a0c6-cc930228954f)

데이터가 적어 에포크를 늘려도 결과 차이가 보이지 않음

```
# 방법 02
class CustomMetricValCallback(MetricValCallback):
    def __init__(self, *args, log_metrics_every_epoch=True, **kwargs):
        super().__init__(*args, **kwargs)
        self.log_metrics_every_epoch = log_metrics_every_epoch

    def on_epoch_end(self, trainer, pl_module):
        if self.log_metrics_every_epoch:
            super().on_epoch_end(trainer, pl_module)
        else:
            # 에포크마다 결과를 구별하여 출력
            print(f"Metrics for epoch {trainer.current_epoch}:")
            for key, value in self.metric_result.items():
                print(f"{key}: {value}")
# (생략)
# val 설정
metric_callback = CustomMetricValCallback(metric=EmbeddingMetrics(extra_keys=["paths"]), log_images=True)
```
결과: 방법 01과 동일

> 02. 모델 파라미터 저장
```
# 모델 저장
checkpoint_path = "trained_model.ckpt"
trainer.save_checkpoint(checkpoint_path)
# trainer.save_checkpoint("trained_model.ckpt")

# (생략)
import torch
import pytorch_lightning as pl
from oml.lightning.modules.extractor import ExtractorModule
from oml.models import ViTExtractor

# 저장된 체크포인트 경로
checkpoint_path = "trained_model.ckpt"

# 저장된 체크포인트 불러오기
checkpoint = torch.load(checkpoint_path)

# 모델에 체크포인트 로드
pl_model.load_state_dict(checkpoint['state_dict'])
```

> 03. SQL 연결 예제
```
# https://docs.python.org/ko/3.8/library/sqlite3.html
# DB 생성
import sqlite3
import numpy as np

# SQLite 데이터베이스 연결
conn = sqlite3.connect('embedding_database.db') # 데이터베이스를 나타내는 Connection 객체를 생성
cursor = conn.cursor()

# 테이블 생성
# https://docs.python.org/ko/3.8/library/sqlite3.html#sqlite3.Cursor.execute
# 단일 SQL문만 실행 하나의 호출로 여러 SQL문을 실행하려면 executescript() 사용
cursor.execute('''CREATE TABLE embeddings
                  (id INTEGER PRIMARY KEY, embedding BLOB)''')

# 예시 임베딩 벡터 생성
embedding_vector = np.random.rand(100)

# 임베딩 벡터를 바이너리로 변환하여 데이터베이스에 삽입
cursor.execute("INSERT INTO embeddings (embedding) VALUES (?)", (sqlite3.Binary(embedding_vector.tobytes()),))

# 변경사항 저장 및 연결 종료
conn.commit()
conn.close()
```
```
# DB 출력
import sqlite3

# SQLite 데이터베이스 연결
conn = sqlite3.connect('embedding_database.db')
cursor = conn.cursor()

# 테이블의 열 이름 가져오기
# # https://www.sqlite.org/pragma.html # SQLite 관련 SQL 확장으로, SQLite 라이브러리의 작업을 수정하거나 SQLite 라이브러리에 내부(테이블이 아닌) 데이터를 쿼리하는 데 사용
# https://docs.python.org/ko/3.8/library/sqlite3.html#sqlite3.Cursor.fetchall # 질의 결과의 모든 (남은) 행을 가져와서 리스트를 반환
cursor.execute("PRAGMA table_info(embeddings)") # 명명된 테이블의 각 일반 열에 대해 하나의 행을 반환
columns = cursor.fetchall()
column_names = [column[1] for column in columns]

# 테이블에서 모든 값 가져오기
cursor.execute("SELECT * FROM embeddings")
rows = cursor.fetchall()

# SQL 형식으로 출력
print("SQL 형식으로 데이터 출력:")
for row in rows:
    values = ", ".join([f"'{value}'" if isinstance(value, str) else str(value) for value in row])
    print(f"INSERT INTO embeddings ({', '.join(column_names)}) VALUES ({values});")

# 연결 종료
conn.close()
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/b910d931-8542-4ec6-bee3-466cb28c0e64)


```
# 시각화
import sqlite3
import numpy as np
import matplotlib.pyplot as plt

def load_embeddings_from_database(database_path):
    conn = sqlite3.connect(database_path)
    cursor = conn.cursor()
    cursor.execute("SELECT id, embedding FROM embeddings")
    rows = cursor.fetchall()
    embeddings = {}
    for row in rows:
        id, embedding_bytes = row
        embedding_vector = np.frombuffer(embedding_bytes, dtype=np.float64) # 버퍼를 1차원 배열로 해석
        embeddings[id] = embedding_vector
    conn.close()
    return embeddings

def calculate_distances(query_vector, embeddings):
  # https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html#numpy-linalg-norm
    distances = {}
    for id, embedding_vector in embeddings.items():
        distance = np.linalg.norm(query_vector - embedding_vector)
        distances[id] = distance
    return distances

def visualize_top_k_matches(query_vector, top_k_ids, embeddings):
    fig, axes = plt.subplots(1, len(top_k_ids) + 1, figsize=(15, 3))
    axes[0].imshow(query_vector.reshape(10, 10), cmap='viridis')
    axes[0].set_title('Query Vector')
    for i, id in enumerate(top_k_ids, 1):
        embedding_vector = embeddings[id]
        axes[i].imshow(embedding_vector.reshape(10, 10), cmap='viridis')
        axes[i].set_title(f'Top {i} Match (ID: {id})')
    plt.show()

def find_top_k_matches(query_vector, embeddings, k=5):
    distances = calculate_distances(query_vector, embeddings)
    top_k_ids = sorted(distances, key=distances.get)[:k]
    return top_k_ids

if __name__ == "__main__":
    database_path = 'embedding_database.db'
    embeddings = load_embeddings_from_database(database_path)

    # 임의의 쿼리 벡터 생성 (여기서는 랜덤 벡터로 대체)
    query_vector = np.random.rand(100)

    # 상위 k개의 매칭 찾기
    top_k_ids = find_top_k_matches(query_vector, embeddings)

    # 결과 시각화
    visualize_top_k_matches(query_vector, top_k_ids, embeddings)
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/02698de5-ba1e-40cf-b04b-c3f00dde881c)

> 04. [postprocessor 예제](https://colab.research.google.com/drive/1LBmusxwo8dPqWznmK627GNMzeDVdjMwv?usp=sharing)
```
# https://pytorch.org/vision/0.8/transforms.html # 원본 추정
# https://pytorch.org/vision/0.8/_modules/torchvision/transforms/transforms.html#Resize
transform = get_normalisation_resize_torch(im_size=64)
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/1ffb6a89-0600-4376-b3ce-612a3d31db1f)

```
embeddings_train, embeddings_val, df_train, df_val = \
    inference_on_dataframe(dataset_root, "df.csv", extractor=extractor, transforms=transform)
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/4e2ee06f-c6fe-49d7-8575-958d5149c19f)

```
# https://open-metric-learning.readthedocs.io/en/latest/contents/models.html#concatsiamese
# 이 모델은 두 개의 입력을 연결하여 주어진 백본에 통과시키고 그 후에 헤드를 적용
siamese = ConcatSiamese(extractor=extractor, mlp_hidden_dims=[100])
```
![image](https://github.com/Suyeon-j/study_oml/assets/66247203/36baca42-4aca-43cb-a9a5-bfdfabde2405)

```
# https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html
# https://ok-lab.tistory.com/241
# Sigmoid 레이어와 BCELoss를 하나의 클래스로 결합한 것
criterion = BCEWithLogitsLoss()
```
```
# https://open-metric-learning.readthedocs.io/en/latest/contents/postprocessing.html#pairwiseimagespostprocessor
# 쿼리와 쿼리에 가장 가까운 상위 n개 갤러리 사이의 거리를 다시 추정
postprocessor = PairwiseImagesPostprocessor(top_n=3, pairwise_model=siamese, transforms=transform)
```
